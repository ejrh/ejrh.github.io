---
layout: post
title: Enumerating regular languages
date: 2011-06-14 08:04:18.000000000 +12:00
categories:
- Programming
tags:
- python
- regular expression
status: publish
type: post
published: true
meta:
  _edit_last: '14086420'
  tagazine-media: a:7:{s:7:"primary";s:0:"";s:6:"images";a:1:{s:106:"http://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Pairing_natural.svg/220px-Pairing_natural.svg.png";a:6:{s:8:"file_url";s:106:"http://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Pairing_natural.svg/220px-Pairing_natural.svg.png";s:5:"width";s:3:"220";s:6:"height";s:3:"218";s:4:"type";s:5:"image";s:4:"area";s:5:"47960";s:9:"file_path";s:0:"";}}s:6:"videos";a:0:{}s:11:"image_count";s:1:"1";s:6:"author";s:8:"14086420";s:7:"blog_id";s:8:"19263352";s:9:"mod_stamp";s:19:"2011-06-13
    20:04:18";}
  _wpas_skip_yup: '1'
  _wpas_skip_ms: '1'
  _wpas_skip_linkedin: '1'
  _wpas_skip_1984850: '1'
  _wpas_skip_404107: '1'
author: 
---
<p style="text-align:justify;">How the countability of the rational numbers implies an enumeration for regular languages.<br />
<!--more--></p>
<p style="text-align:justify;">Someone posted in r/programming a link to <a title="regex-genex discussion in r/programming on Reddit" href="http://www.reddit.com/r/programming/comments/hya57/from_a_regex_generate_all_possible_strings_it_can/">regex-genex</a>, which is a Haskell library for generating all sentences from a regular expression. It's an interesting computational problem, which I encountered when I worked on a similar program.</p>
<p style="text-align:justify;">A while ago I wrote a Python program for drawing state diagrams from regular expressions. It would parse the expression into a structure, apply all those amazing RE -&gt; GFA -&gt; NFA -&gt; DFA transformations on it, then pipe a description of the result to <a title="GraphViz home page" href="http://www.graphviz.org/">GraphViz</a>. Unfortunately I've lost the source but I fondly remember working on a method to generate the strings matching an expression. Seeing this on Reddit brought to mind the trickiness of doing this properly, and I thought I'd try to recreate some of the solution here. (These regular expressions are the pure ones I was taught in computer science, with simple concatenation, grouping and + and * operations. I use literals such a and b to represent arbitrary subexpressions rather than concrete symbols.)</p>
<p style="text-align:justify;">There are three operations in <a title="Regular expression at Wikipedia" href="http://en.wikipedia.org/wiki/Regular_expression">regular expression</a> construction:</p>
<ul style="text-align:justify;">
<li>Alternation. L(a+b) is the union of L(a) and L(b). (For some purposes languages behave more like bags than sets, so if a word appears in both L(a) and L(b) it may appear twice in the union)</li>
<li>Concatenation. L(ab) is the set of all possible ways of concatenating a word in L(a) with one from L(b); it's the Cartesian product of those two underlying languages.</li>
<li><a title="Kleene star at Wikipedia" href="http://en.wikipedia.org/wiki/Kleene_star">Kleene star</a>. L(a*) is the set of any words that are any finite concatenation of words in L(a). If L(a) is not empty, then L(a*) is an infinite set.</li>
</ul>
<p style="text-align:justify;">So, some regular languages are infinite. Therefore, enumeration of the words in them has to be done lazily if it is done at all. In a lazy implementation, every element of the set should be returned "eventually". Even then you have to ensure that <em>eventually</em> means within a finite number of steps for any given element. That's not always easy!</p>
<p style="text-align:justify;">In the case of alternation, L(a+b) can be generated for finite underlying languages easily enough:</p>
<p>[sourcecode language="python"]def generate_alt(re1, re2):<br />
    for w in generate(re1):<br />
        yield w<br />
    for w in generate(re2):<br />
        yield w[/sourcecode]</p>
<p style="text-align:justify;">But if L(a) is infinite, nothing in L(b) will ever be generated. It's easy to fix in this case, by alternately picking elements from each:</p>
<p>[sourcecode language="python"]def generate_alt(re1, re2):<br />
    for w1,w2 in izip_longest(generate(re1), generate(re2)):<br />
        if w1 is not None:<br />
            yield w1<br />
        if w2 is not None:<br />
            yield w2[/sourcecode]</p>
<p style="text-align:justify;">(It's a bit messy because we need to handle the cases of two finite sequences, finite and infinite sequences, and two infinite sequences.)</p>
<p style="text-align:justify;">Or take the alternation ab. The language for this, L(ab) is the cartesian product of L(a) and L(b). When we're talking about finite languages, this can be generated simply by a couple of nested loops over L(a) and L(b):</p>
<p>[sourcecode language="python"]def generate_concat(re1, re2):<br />
    for w1 in generate(re1):<br />
        for w2 in generate(re2):<br />
            yield '%s%s' % (w1, w2)[/sourcecode]</p>
<p style="text-align:justify;">What about L(a*b*) ? The problem is that the outer loop's first iteration will never end, because the inner loop will continue forever. The generator will continue to spit out valid words in L(ab), but only the ones starting with the first word in L(a). The others will have to wait until those ones are exhausted, which, given there's an infinite supply of them, puts the time of their arrival somewhat at odds with the notion of "eventually". We need to iterative over both underlying languages in a way that covers all pairs of elements.</p>
<p style="text-align:justify;">The two underlying languages are countably infinite sets; so finding L(a*b*) is akin to a proof-by-construction that their product is also <a title="Countable set at Wikipedia" href="http://en.wikipedia.org/wiki/Countable_set">countable</a>. It's essentially the same as proving that the rational numbers are countable, by finding a mapping from them to the natural numbers. This can be done by drawing a one-dimensional path through the two-dimensional matrix of rational numbers, as done by Cantor's <a title="Cantor's Pairing function at Wikipedia" href="http://en.wikipedia.org/wiki/Cantor_pairing_function#Cantor_pairing_function">pairing function</a>:</p>
<p>[caption id="" align="aligncenter" width="220" caption="Cantor&#039;s pairing function, mapping pairs of natural numbers to natural numbers"]<img title="Cantor's pairing function (image from Wikipedia)" src="assets/220px-Pairing_natural.svg.png" alt="" width="220" height="218" />[/caption]</p>
<p style="text-align:justify;">We want a similar function from pairs of regular expressions to some countable set; if we assume the two sets are countable, then there is a mapping from each regexp to a natural number, and we can use the same function to map the pair of these to a natural number. Finally, that number determines the generation order of that pair of elements:</p>
<p>[sourcecode language="python"]def generate_concat(re1, re2):<br />
    q = []<br />
    for wq in generate(re1):<br />
       # Every outer iteration, a word is taken from re1<br />
       q.append(wq)<br />
       # Then we iterate over that in reverse, at the same time as we take elements from re2<br />
       # Iteration over generate(re2) will be limited to the length of q<br />
       for w1,w2 in izip(reversed(q), generate(re2)):<br />
            yield '%s%s' % (w1, w2)[/sourcecode]</p>
<p style="text-align:justify;">By construction, this implements lazy, eventual generation of elements in regular expressions containing alternation and concatenation. It also handles infinite underlying languages such as those defined by the Kleene star; the problem is that we haven't defined the generator for that case.</p>
<p style="text-align:justify;">If L(a) is finite, L(a*) can be generated using the recursive relation: L(a*) = L(e + aa*) (where e is the empty string).</p>
<p>[sourcecode language="python"]def generate_star(re1):<br />
    yield ''<br />
    for w1 in generate(re1):<br />
        for w2 in generate_star(re1):<br />
            yield '%s%s' % (w1, w2)[/sourcecode]</p>
<p style="text-align:justify;">For infinite L(a), we can combine this with the solution for concatenation over infinite languages:</p>
<p>[sourcecode language="python"]def generate_star(re1):<br />
    yield ''<br />
    q = []<br />
    for wq in generate(re1):<br />
       q.append(wq)<br />
       for w1,w2 in izip(reversed(q), generate_star(re1)):<br />
            yield '%s%s' % (w1, w2)[/sourcecode]</p>
<p style="text-align:justify;">When we generated concatenated regexps, we drew a zigzagging diagonal path over the pairs of words from each underlying language. What is the shape of the path over a Kleene star? It's not three-dimensional; it has an indefinite number of dimensions! Each level of recursion in the above function adds a dimension, and each dimension corresponds to an additional enumeration of L(a).</p>
<p style="text-align:justify;">The need to invoke countability theorems in enumerating regular expressions is surprisingly involved. And I don't remember using it when I wrote my first implementation! So either that implementation was buggy (in the sense of not generating all words "eventually"), or there's a simple trick I'm missing! Or maybe both are true...</p>
<p style="text-align:justify;"><strong>Update.</strong> <a title="Enumerating regular expressions on Reddit" href="http://www.reddit.com/r/programming/comments/hzk6d/enumerating_regular_languages_thoughts_arising/">Posted</a> to Reddit but fumbled the intro paragraph.Â  665 visits and 0 comments!</p>
